# -*- coding: utf-8 -*-
"""lab tutorial 5 - Juan Espinosa.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1C8nZZtGZ6Nfi6kmASJlhRxrt47u0W-68

# MACHINE LEARNING LAB - TUTORIAL 5
---
## Juan Fernando Espinosa
## 303158

---

# 1. PRE-PROCESS GIVEN DATASETS
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
from numpy import random
# %matplotlib inline
import math
import matplotlib.pyplot as plt
from google.colab import files
from google.colab import drive
from mpl_toolkits.mplot3d import Axes3D

# Importing Bank CSV
drive.mount('/content/drive')
!ls "/content/drive/My Drive/Colab Notebooks/LAB/tutorial 5/bank.csv"

# Importing Wine Quality - red
drive.mount('/content/drive')
!ls "/content/drive/My Drive/Colab Notebooks/LAB/tutorial 5/winequality-red.csv"

# Importing Wine Quality - white
drive.mount('/content/drive')
!ls "/content/drive/My Drive/Colab Notebooks/LAB/tutorial 5/winequality-white.csv"

"""## 1.1 Pre-processing Bank Dataset"""

missing_values = ['-','na','Nan','nan','n/a','?']
bank = pd.read_csv('/content/drive/My Drive/Colab Notebooks/LAB/tutorial 5/bank.csv', sep=';', na_values = missing_values)

bank.head()

# Check for missing or incongruent values
check = bank.empty
print('checking missing values:',check)
print('Sum of errors:',bank.isnull().sum())

"""> convert non-numeric data into numeric one using dummies. Bear into account that it is not feasible to get dummies to the target column. Therefore, replacing the classification with {0, 1} it is an adequate action."""

#transform the y column into numeric 0 and 1
print(bank["y"].value_counts())
bank['y'] = bank['y'].replace(['no', 'yes'], [0, 1])

# Encoding the information with get_dummies.
bank = pd.get_dummies(bank) 
bank.head()

"""> Normalizing the dataset before splitting"""

# Bearing in mind the feedback given in the previous lab, the "y" column is not normalized.
def normalize(dataset):
    dataNorm=((dataset-dataset.min())/(dataset.max()-dataset.min()))
    dataNorm["y"]=dataset["y"]
    return dataNorm

data = normalize(bank)
data.head()

"""> Split into train (80%) and test (20%) sets"""

bank_train = data.sample(frac=0.8)
bank_test = data.drop(bank_train.index)

"""## 1.2 Pre-processing Wine quality-red and Wine Quality-white Datasets"""

missing_values = ['-','na','Nan','nan','n/a','?']
red_wine = pd.read_csv('/content/drive/My Drive/Colab Notebooks/LAB/tutorial 5/winequality-red.csv', sep=';', na_values = missing_values)
red_wine.head()

missing_values = ['-','na','Nan','nan','n/a','?']
white_wine = pd.read_csv('/content/drive/My Drive/Colab Notebooks/LAB/tutorial 5/winequality-white.csv', sep=';', na_values = missing_values)
white_wine.head()

"""> Concatenating both white and red wine datasets

Given two datasets with similar number of columns and considering that the objective is to measure Wine quality no matter the type of wine, the decision of concatenating both datasets helps me to accomplish the goal
"""

frames = [red_wine, white_wine]
wine_quality = pd.concat(frames)
wine_quality.head()

# Check for missing or incongruent values
check = wine_quality.empty
print('checking missing values:',check)
print('Sum of errors:',wine_quality.isnull().sum())

"""> Convert non-numeric data into numeric ones using "Get Dummies""""

wine_quality.dtypes

"""All the columns in the dataframe are numeric, therefore, no need of encoding.

> Normalizing the dataset
"""

def normalize(dataset):
    dataNorm=((dataset-dataset.min())/(dataset.max()-dataset.min()))
    dataNorm["quality"]=dataset["quality"]
    return dataNorm
wine = normalize(wine_quality)
wine.head()

"""> Split into train (80%) and test (20%) sets"""

wine_train = wine.sample(frac=0.8)
wine_test = wine.drop(wine_train.index)

"""# To maintain order and information flow exercise 2 and 3 are going to be presented for each dataset separately.

# BANK DATASET

---

## 2.  LINEAR CLASSIFICATION WITH GRADIENT DESCENT

---

## First, presentation of the main functions and model for Linear Classification with Gradient Descent.
"""

# Function to get the minibatches.
def mini_batch(X, y, batch_size):
  #mini_batches = []
  random_index = random.choice(len(y), len(y), replace=False)
  X_shuffle = X[random_index,:]
  y_shuffle = y[random_index,:]
  mini_batches = [(X_shuffle[i:i+batch_size,:], y_shuffle[i:i+batch_size]) for i in range(0, len(y), batch_size)]
  return mini_batches

# Function that measures the derivative of f(beta).
def gradient(X, y, beta, parameter):
  gradient = ((2/X.shape[0])*(X.T@(X@beta - y))+ 2*parameter*beta)
  return gradient

# Function that measures the loss function for the betas.
def loss_function(X, y, beta, parameter):
  loss = ((1/X.shape[0])*np.dot((y - X@beta).T,(y - X@beta))) + parameter*np.dot(beta.T, beta)
  return loss

# Function that measures the error of the model.
def RMSE_function(X, y, beta):
  error = np.sqrt(np.sum((y - X@beta)**2)/X.shape[0])
  return error

#Body of the algorithm: Stochastic Gradient Descent with fixed learning rate.

def SGD(X, y, x_test, y_test, u, parameter, batch_size, num_iters, beta):
  RMSE_epoch = []
  RMSE_test  = {}
  loss = loss_function(X, y, beta, parameter)

  for i in range(num_iters):
      mini_batches = mini_batch(X, y, batch_size)
      for j in mini_batches:
        X_mini = j[0]
        y_mini = j[1]
        beta_hat = beta - u*gradient(X_mini, y_mini, beta, parameter)
        loss_old = loss
        loss = loss_function(X_mini, y_mini, beta_hat, parameter)
        beta = beta_hat
      error = RMSE_function(X, y, beta_hat)
      RMSE_epoch.append(error)
      RMSE_test[i] = RMSE_function(x_test, y_test, beta_hat)

  return beta_hat, RMSE_epoch, RMSE_test

"""### **Learning rate =** 0.00001 and **Lambda=** 0.01 | 100 iterations"""

y = bank_train['y'].values
y = np.reshape(y, (len(y),1))
X = bank_train.drop(['y'], axis=1).values
column_one = np.ones((X.shape[0],1))
X = np.concatenate((column_one, X), axis = 1)
n = X.shape[1]
beta = np.zeros(n)
beta = np.reshape(beta, (len(beta),1))
y1 = bank_test['y'].values
y1 = np.reshape(y1, (len(y1),1))
X1 = bank_test.drop(['y'], axis=1).values
column_one = np.ones((X1.shape[0],1))
X1 = np.concatenate((column_one, X1), axis = 1)

betas, RMSE, RMSE_test = SGD(X, y, X1, y1, 0.00001, 0.01, 50, 100, beta)
print('betas', betas.T,'\n', 'RMSE',RMSE, '\n', 'RMSE',RMSE_test)

fig, ax1 = plt.subplots(1,1,figsize=(12,6))
color = 'tab:red'
ax1.set_xlabel('iterations')
ax1.set_ylabel('RMSE Train', color=color)
ax1.plot(range(100), RMSE, color=color)
ax1.tick_params(axis='y', labelcolor=color)
ax1.legend(['RMSE Train'], bbox_to_anchor=(1,0.99))

ax2 = ax1.twinx()
lista = RMSE_test.items()
x,y = zip(*lista)

color = 'tab:blue'
ax2.set_ylabel('RMSE test set', color=color)
ax2.plot(x, y, '--', color=color, alpha=0.9)
ax2.tick_params(axis='y', labelcolor=color)
ax2.legend(['RMSE Test'], bbox_to_anchor=(1,0.93))
plt.title('Learning rate = 0.00001 and Lambda= 0.001', fontdict=None, loc='center', pad=None)
fig.tight_layout() 
plt.show()

"""### **Learning rate =** 0.0001 and **Lambda=** 0.1 | 100 iterations"""

y = bank_train['y'].values
y = np.reshape(y, (len(y),1))
X = bank_train.drop(['y'], axis=1).values
column_one = np.ones((X.shape[0],1))
X = np.concatenate((column_one, X), axis = 1)
n = X.shape[1]
beta = np.zeros(n)
beta = np.reshape(beta, (len(beta),1))
y1 = bank_test['y'].values
y1 = np.reshape(y1, (len(y1),1))
X1 = bank_test.drop(['y'], axis=1).values
column_one = np.ones((X1.shape[0],1))
X1 = np.concatenate((column_one, X1), axis = 1)

betas1, RMSE1, RMSE_test1 = SGD(X, y, X1, y1, 0.0001, 0.1, 50, 100, beta)
print('betas', betas1.T,'\n', 'RMSE',RMSE1)

fig, ax1 = plt.subplots(1,1,figsize=(12,6))
color = 'tab:red'
ax1.set_xlabel('iterations')
ax1.set_ylabel('RMSE Train', color=color)
ax1.plot(range(100), RMSE1, color=color)
ax1.tick_params(axis='y', labelcolor=color)
ax1.legend(['RMSE Train'], bbox_to_anchor=(1,0.99))

ax2 = ax1.twinx()
lista = RMSE_test1.items()
xx,yy = zip(*lista)

color = 'tab:blue'
ax2.set_ylabel('RMSE test set', color=color)
ax2.plot(xx, yy, '--', color=color, alpha=0.9)
ax2.tick_params(axis='y', labelcolor=color)
ax2.legend(['RMSE Test'], bbox_to_anchor=(1,0.93))
plt.title('Learning rate = 0.0001 and Lambda= 0.1', fontdict=None, loc='center', pad=None)
fig.tight_layout() 
plt.show()

"""### **Learning rate =** 0.001 and **Lambda=** 1 | 100 iterations"""

y = bank_train['y'].values
y = np.reshape(y, (len(y),1))
X = bank_train.drop(['y'], axis=1).values
column_one = np.ones((X.shape[0],1))
X = np.concatenate((column_one, X), axis = 1)
n = X.shape[1]
beta = np.zeros(n)
beta = np.reshape(beta, (len(beta),1))
y1 = bank_test['y'].values
y1 = np.reshape(y1, (len(y1),1))
X1 = bank_test.drop(['y'], axis=1).values
column_one = np.ones((X1.shape[0],1))
X1 = np.concatenate((column_one, X1), axis = 1)

betas2, RMSE2, RMSE_test2 = SGD(X, y, X1, y1, 0.001, 1, 50, 100, beta)
print('betas', betas1.T,'\n', 'RMSE',RMSE1)

fig, ax1 = plt.subplots(1,1,figsize=(12,6))
color = 'tab:red'
ax1.set_xlabel('iterations')
ax1.set_ylabel('RMSE Train', color=color)
ax1.plot(range(100), RMSE2, color=color)
ax1.tick_params(axis='y', labelcolor=color)
ax1.legend(['RMSE Train'], bbox_to_anchor=(1,0.99))

ax2 = ax1.twinx()
lista = RMSE_test2.items()
xxx,yyy = zip(*lista)

color = 'tab:blue'
ax2.set_ylabel('RMSE test set', color=color)
ax2.plot(xxx, yyy, '--', color=color, alpha=0.9)
ax2.tick_params(axis='y', labelcolor=color)
ax2.legend(['RMSE Test'], bbox_to_anchor=(1,0.93))
plt.title('Learning rate = 0.001 and Lambda= 1', fontdict=None, loc='center', pad=None)
fig.tight_layout() 
plt.show()

"""## 3. HYPER PARAMETER TUNNING

---

###Hyper-parameter tuning and Cross validation
"""

def cross_validation(data):
  a = [0.0000001, 0.004, 0.003, 0.02]
  parameter = [0.001, 0.03, 0.4, 10]
  pairs = [[r, b] for r in a for b in parameter] # Pairing all learning rate and parameters possible variations
  RMSE_folds = []
  RMSE_avg = []
  RMSE_epoch = []
  hyperparameters = []
  beta = np.zeros(n)
  beta = np.reshape(beta, (len(beta),1))
  
  for i in pairs:
    loss = loss_function(X, y, beta, i[1])
    for j in range(0, len(data), (len(data)//5)):  # Loop to define test and training set considering the folds. 
      test = X[j:j+(len(X)//5)]
      for k in range(0, len(X)):
        if k != j:
          train = X[:k+(len(X))]
      y_train = data['y'].values    # In the next 5 lines, X and Y are being defined. 
      y_train = np.reshape(y_train, (len(y_train),1))
      X_train = data.drop(['y'], axis=1).values
      column_one = np.ones((data.shape[0],1))
      X_train = np.concatenate((column_one, X_train), axis = 1)
      mini_batches = mini_batch(X_train, y_train, 50)
      for j in mini_batches:
        X_mini = j[0]
        y_mini = j[1]
        beta_hat = beta - i[0]*gradient(X_mini, y_mini, beta, i[1])
        loss_old = loss
        loss = loss_function(X_mini, y_mini, beta_hat, i[1])
        beta = beta_hat
    error = RMSE_function(X, y, beta_hat) #measuring error for each epoch
     
    RMSE_epoch.append(error)
    RMSE_folds = sum(RMSE_epoch)/len(RMSE_epoch)  # Average RMSE per fold.
    RMSE_avg.append(RMSE_folds)
    hyperparameters.append(i)
  values = list(zip(RMSE_avg, hyperparameters))
  optimum = min(values)
  return optimum[1], hyperparameters, RMSE_avg

optimum, hyperparameters, RMSE_avg = cross_validation(data)


print('Optimum learning rate and lambda', optimum)

"""> 3D representation of all the combinations of learning rate, lambdas and the Average RMSE."""

param_final=[]
for i in RMSE_avg:
  param = i
  param_final.append(param)

lambdas1 = []
learning = []
for i in hyperparameters:
  learning_rate = i[0]
  lambdas = i[1]
  lambdas1.append(lambdas)
  learning.append(learning_rate)

fig = plt.figure(figsize=(8,8))
ax = fig.add_subplot(111, projection='3d')
ax.scatter(learning, lambdas1, param_final, marker='o')
ax.set_xlabel('Learning rate')
ax.set_ylabel('Lambdas')
ax.set_zlabel('RMSE')
plt.show()

"""## Training the model on complete training data and test data using the optimum learning rate and lambda."""

y = bank_train['y'].values
y = np.reshape(y, (len(y),1))
X = bank_train.drop(['y'], axis=1).values
column_one = np.ones((X.shape[0],1))
X = np.concatenate((column_one, X), axis = 1)
n = X.shape[1]
beta = np.zeros(n)
beta = np.reshape(beta, (len(beta),1))
y1 = bank_test['y'].values
y1 = np.reshape(y1, (len(y1),1))
X1 = bank_test.drop(['y'], axis=1).values
column_one = np.ones((X1.shape[0],1))
X1 = np.concatenate((column_one, X1), axis = 1)

betas, RMSE, RMSE_test = SGD(X, y, X1, y1, 0.01, 0.1, 50, 100, beta)
print('betas', betas.T,'\n', 'RMSE',RMSE)

fig, ax1 = plt.subplots(1,1,figsize=(12,6))
color = 'tab:red'
ax1.set_xlabel('iterations')
ax1.set_ylabel('RMSE Train', color=color)
ax1.plot(range(100), RMSE, color=color)
ax1.tick_params(axis='y', labelcolor=color)
ax1.legend(['RMSE Train'], bbox_to_anchor=(1,0.99))

ax2 = ax1.twinx()
lista = RMSE_test.items()
x1,y1 = zip(*lista)

color = 'tab:blue'
ax2.set_ylabel('RMSE test set', color=color)
ax2.plot(x1, y1, '--', color=color, alpha=0.8)
ax2.tick_params(axis='y', labelcolor=color)
ax2.legend(['RMSE Test'], bbox_to_anchor=(1,0.93))
plt.title('Bank Data optimum Learning Rate and Lambda', fontdict=None, loc='center', pad=None)
fig.tight_layout() 
plt.show()

"""## 4. CONCLUSIONS
---

**Notes:** There is a tiny difference in the graphs above between training data and test data. It is not possible to visualize clearly in the graphs.

1.  The Bank dataset after a simple test has a **bad performance** on unseen data (test set).   

2. There is an obvious relationship between the **Learning rate** and **Lambda**: The bigger the amount of bias you add to the model in order to avoid overfitting the smaller the steps should be kept to guarantee a good generalization (applicable in this exercise).
3.   If a high learning rate is chosen, the model will not be able to work adequately because the bias is going to be high enough and never reaches convergence and the data will be overfitted. 
4.   As it is possible to appreciate the model needs bias to avoid incurring in overfitting. The more bias is added to the data the less number of iterations it needs to reach convergence.
5. The last combination is meaningful: it is necessary to find an **optimal value** of learning rate and lambda, otherwise, one extra unit could make the model to incur in overfitting. 
6. While mixing **Learning rate =** 0.0001 and **Lambda=** 0.1 we can appreciate that the data fits the test set better than the training set. Meaning that the generalization of the model is good. 
6. In exercise 3, after finding the optimal combination the model converges in both training and test sets although there is bias as it is possible to appreciate in curve blue of the graph.

# WINE QUALITY

---

## 2.  LINEAR CLASSIFICATION WITH GRADIENT DESCENT

---

### **Learning rate =** 0.00001 and **Lambda=** 0.1 | 100 iterations
"""

y = wine_train['quality'].values
y = np.reshape(y, (len(y),1))
X = wine_train.drop(['quality'], axis=1).values
column_one = np.ones((X.shape[0],1))
X = np.concatenate((column_one, X), axis = 1)
n = X.shape[1]
beta = np.zeros(n)
beta = np.reshape(beta, (len(beta),1))

y2 = wine_test['quality'].values
y2 = np.reshape(y2, (len(y2),1))
X2 = wine_test.drop(['quality'], axis=1).values
column_one = np.ones((X2.shape[0],1))
X2 = np.concatenate((column_one, X2), axis = 1)

betas, RMSE, RMSE_test3 = SGD(X, y, X2, y2, 0.00001, 0.1, 50, 100, beta)
print('betas', betas.T,'\n', 'RMSE',RMSE)

fig, ax1 = plt.subplots(1,1,figsize=(12,6))
color = 'tab:red'
ax1.set_xlabel('iterations')
ax1.set_ylabel('RMSE Train', color=color)
ax1.plot(range(100), RMSE, color=color, alpha=0.8)
ax1.tick_params(axis='y', labelcolor=color)
ax1.legend(['RMSE Train'], bbox_to_anchor=(1,0.99))

ax2 = ax1.twinx()
lista = RMSE_test3.items()
x,y = zip(*lista)

color = 'tab:blue'
ax2.set_ylabel('RMSE test set', color=color)
ax2.plot(x, y, '--', color=color, alpha=1)
ax2.tick_params(axis='y', labelcolor=color)
ax2.legend(['RMSE Test'], bbox_to_anchor=(1,0.93))
plt.title('Learning rate =** 0.00001 and Lambda= 0.1', fontdict=None, loc='center', pad=None)
fig.tight_layout() 
plt.show()

"""### **Learning rate =** 0.001 and **Lambda=** 1 | 100 iterations"""

y = wine_train['quality'].values
y = np.reshape(y, (len(y),1))
X = wine_train.drop(['quality'], axis=1).values
column_one = np.ones((X.shape[0],1))
X = np.concatenate((column_one, X), axis = 1)
n = X.shape[1]
beta = np.zeros(n)
beta = np.reshape(beta, (len(beta),1))

y2 = wine_test['quality'].values
y2 = np.reshape(y2, (len(y2),1))
X2 = wine_test.drop(['quality'], axis=1).values
column_one = np.ones((X2.shape[0],1))
X2 = np.concatenate((column_one, X2), axis = 1)

betas, RMSE, RMSE_test4 = SGD(X, y, X2, y2, 0.0001, 1, 50, 100, beta)
print('betas', betas.T,'\n', 'RMSE',RMSE)

fig, ax1 = plt.subplots(1,1,figsize=(12,6))
color = 'tab:red'
ax1.set_xlabel('iterations')
ax1.set_ylabel('RMSE Train', color=color)
ax1.plot(range(100), RMSE, color=color)
ax1.tick_params(axis='y', labelcolor=color)
ax1.legend(['RMSE Train'], bbox_to_anchor=(1,0.99))

ax2 = ax1.twinx()
lista = RMSE_test4.items()
xx,yy = zip(*lista)

color = 'tab:blue'
ax2.set_ylabel('RMSE test set', color=color)
ax2.plot(xx, yy, '--', color=color, alpha=0.9)
ax2.tick_params(axis='y', labelcolor=color)
ax2.legend(['RMSE Test'], bbox_to_anchor=(1,0.93))
plt.title('Learning rate = 0.001 and Lambda= 1', fontdict=None, loc='center', pad=None)
fig.tight_layout() 
plt.show()

"""### **Learning rate =** 0.01 and **Lambda=** 10 | 100 iterations

I chose a high number of lambda in order to appreciate the effect the data will experience if the regularization is added more than the optimal.
"""

y = wine_train['quality'].values
y = np.reshape(y, (len(y),1))
X = wine_train.drop(['quality'], axis=1).values
column_one = np.ones((X.shape[0],1))
X = np.concatenate((column_one, X), axis = 1)
n = X.shape[1]
beta = np.zeros(n)
beta = np.reshape(beta, (len(beta),1))

y2 = wine_test['quality'].values
y2 = np.reshape(y2, (len(y2),1))
X2 = wine_test.drop(['quality'], axis=1).values
column_one = np.ones((X2.shape[0],1))
X2 = np.concatenate((column_one, X2), axis = 1)

betas, RMSE, RMSE_test5 = SGD(X, y, X2, y2, 0.01, 10, 50, 100, beta)
print('betas', betas.T,'\n', 'RMSE',RMSE)

fig, ax1 = plt.subplots(1,1,figsize=(12,6))
color = 'tab:red'
ax1.set_xlabel('iterations')
ax1.set_ylabel('RMSE Train', color=color)
ax1.plot(range(100), RMSE, color=color)
ax1.tick_params(axis='y', labelcolor=color)

ax2 = ax1.twinx()
lista = RMSE_test5.items()
xxx,yyy = zip(*lista)

color = 'tab:blue'
ax2.set_ylabel('RMSE test set', color=color)
ax2.plot(xxx, yyy, '--', color=color, alpha=0.9)
ax2.tick_params(axis='y', labelcolor=color)
plt.title('Learning rate = 0.01 and Lambda= 10', fontdict=None, loc='center', pad=None)
fig.tight_layout() 
plt.show()

"""## 3. HYPER PARAMETER TUNNING

---

###Hyper-parameter tuning and Cross validation
"""

def cross_validation(data):
  a = [0.001, 0.000001, 0.0001, 0.0001]
  parameter = [0.1, 0.01, 1, 10]
  pairs = [[r, b] for r in a for b in parameter] # Pairing all learning rate and parameters possible variations
  RMSE_folds = []
  RMSE_avg = []
  RMSE_epoch = []
  hyperparameters = []
  beta = np.zeros(n)
  beta = np.reshape(beta, (len(beta),1))
  
  for i in pairs:
    loss = loss_function(X, y, beta, i[1])
    for j in range(0, len(data), (len(data)//5)): # Loop to define test and training set considering the folds. 
      test = X[j:j+(len(X)//5)]
      for k in range(0, len(X)):
        if k != j:
          train = X[:k+(len(X))]
      y_train = data['quality'].values        # In the next 5 lines, X and Y are being defined. 
      y_train = np.reshape(y_train, (len(y_train),1))

      X_train = data.drop(['quality'], axis=1).values
      column_one = np.ones((data.shape[0],1))
      X_train = np.concatenate((column_one, X_train), axis = 1)
      mini_batches = mini_batch(X_train, y_train, 50)
      for j in mini_batches:
        X_mini = j[0]
        y_mini = j[1]
        beta_hat = beta - i[0]*gradient(X_mini, y_mini, beta, i[1])
        loss_old = loss
        loss = loss_function(X_mini, y_mini, beta_hat, i[1])
        beta = beta_hat
      error = RMSE_function(X, y, beta_hat)
      RMSE_epoch.append(error)
    RMSE_folds = sum(RMSE_epoch)/len(RMSE_epoch)     # Average RMSE per fold.
    RMSE_avg.append(RMSE_folds)
    
    hyperparameters.append(i)
  values = list(zip(RMSE_avg, hyperparameters))
  optimum = min(values)
  return optimum[1], hyperparameters, RMSE_avg

optimum, hyperparameters, RMSE_avg = cross_validation(wine)

for i in hyperparameters:
  learning_rate = i[0]
  lambdas = i[1]

print('Optimum learning rate and lambda', optimum)

"""> 3D representation of all the combinations of learning rate, lambdas and the Average RMSE."""

param_final=[]
for i in RMSE_avg:
  param = i
  param_final.append(param)

lambdas1 = []
learning = []
for i in hyperparameters:
  learning_rate = i[0]
  lambdas = i[1]
  lambdas1.append(lambdas)
  learning.append(learning_rate)

fig = plt.figure(figsize=(8,8))
ax = fig.add_subplot(111, projection='3d')
ax.scatter(learning, lambdas1, param_final, marker='o')
ax.set_xlabel('Learning rate')
ax.set_ylabel('Lambdas')
ax.set_zlabel('RMSE')
plt.show()

"""## Training the model on complete training data and test data using the optimum learning rate and lambda."""

y = wine_train['quality'].values
y = np.reshape(y, (len(y),1))
X = wine_train.drop(['quality'], axis=1).values
column_one = np.ones((X.shape[0],1))
X = np.concatenate((column_one, X), axis = 1)
n = X.shape[1]
beta = np.zeros(n)
beta = np.reshape(beta, (len(beta),1))

y2 = wine_test['quality'].values
y2 = np.reshape(y2, (len(y2),1))
X2 = wine_test.drop(['quality'], axis=1).values
column_one = np.ones((X2.shape[0],1))
X2 = np.concatenate((column_one, X2), axis = 1)


betas, RMSE_wine, RMSE_test_wine = SGD(X, y, X2, y2, 0.001, 0.01, 50, 100, beta)
print('betas', betas.T,'\n', 'RMSE',RMSE)

fig, ax1 = plt.subplots(1,1,figsize=(12,6))
color = 'tab:red'
ax1.set_xlabel('iterations')
ax1.set_ylabel('RMSE Train', color=color)
ax1.plot(range(100), RMSE_wine, color=color)
ax1.tick_params(axis='y', labelcolor=color)
ax1.legend(['RMSE Train'], bbox_to_anchor=(1,0.99))

ax2 = ax1.twinx()
lista = RMSE_test_wine.items()
xs,ys = zip(*lista)

color = 'tab:blue'
ax2.set_ylabel('RMSE test set', color=color)
ax2.plot(xs, ys, '--',color=color, alpha=1)
ax2.tick_params(axis='y', labelcolor=color)
ax2.legend(['RMSE Test'], bbox_to_anchor=(1,0.93))
plt.title('Wine Data optimum Learning Rate and Lambda', fontdict=None, loc='center', pad=None)
fig.tight_layout() 
plt.show()

"""## 4. CONCLUSIONS
---

1.  The Wine quality dataset has a **good performance** on unseen data (test set). In other words, it is not incurring in overfitting.   

2. The opposite effect happens with this dataset: since the data generalizes well it requires small bias to improve the model and reach convergence accurately. 
3.   The last combination of **learning rate** and **lambda** shows the consequences of adding more bias to a model when it is not required: Never reaches convergence and overfitting takes place. 
4.   By checking the previous conclusion, on exercise 3 an **ideal combination** must be selected. The output is a relative low learning rate and lambda. The number of iterations is reduced sharply while picking an optimal lambda and learning rate.

# BIBLIOGRAPHY
---

> Stochastic Gradient Descent - Mini-batch and more - Adventures in Machine Learning. (2019). Retrieved 27 November 2019, from https://adventuresinmachinelearning.com/stochastic-gradient-descent/
"""